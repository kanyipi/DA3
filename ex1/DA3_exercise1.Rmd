---
title: \vspace{-0.75cm} DA3 Exercise1
author: Peter Kaiser
date: '2022 01 23 '
output: pdf_document
---

# Introduction

This is a report about building models to predict the hourly wage of the driving jobs with multiple predictor variables in the cps data set. In the end we horse race the models to see which is the best one. It checks the BIC and the RMSE on the whole data set and the RMSE with 4 fold cross validation.

```{r, echo=FALSE, message=FALSE}
# setup and data import

library(tidyverse)
library(fixest)
library(caret)
library(knitr)
library(kableExtra)
library(egg)


df_all <- read_csv("https://osf.io/4ay9x/download")
```

```{r, echo=FALSE}
# select predictor columns
df <- df_all %>% select(occ2012, earnwke, uhours, grade92, race, age, sex, marital, unionmme)

# counting NA fields
na_count <- sum(is.na(df))

# filtering for driving occupation and the filters we applied in class
df <- df %>% filter(occ2012 == 9120 | occ2012 == 9130 | occ2012 == 9140)

df <- df %>% filter(uhours >= 20, earnwke > 0, age >= 24, age <= 64)

pre_count <- df %>% nrow()

df <- df %>% filter(grade92 >= 39, grade92 < 43)

post_count <- df %>% nrow()

filtered <- pre_count - post_count

## Data munging
# hourly wage
df <- df %>% mutate(earnho = earnwke / uhours)

# education
df <- df %>% mutate(e_highschoolf = ifelse(grade92 == 39, 1, 0))
df <- df %>% mutate(e_collegedrop = ifelse(grade92 == 40, 1, 0))
df <- df %>% mutate(e_occupationdegree = ifelse(grade92 == 41, 1, 0))
df <- df %>% mutate(e_academicdegree = ifelse(grade92 == 42, 1, 0))

df <- df %>% mutate(r_white = ifelse(race == 1, 1, 0))
df <- df %>% mutate(r_blackf = ifelse(race == 2, 1, 0))
df <- df %>% mutate(r_asianf = ifelse(race == 4, 1, 0))
df <- df %>% mutate(r_otherf = ifelse(race != 1 &
  race != 2 &
  race != 4, 1, 0))

# sex
df <- df %>% mutate(s_malef = ifelse(sex == 1, 1, 0))
df <- df %>% mutate(s_femalef = ifelse(sex == 2, 1, 0))

# marital
df <- df %>% mutate(m_marriedf = ifelse(marital == 1, 1, 0))
df <- df %>% mutate(m_divorcedf = ifelse(marital == 5, 1, 0))
df <- df %>% mutate(m_nevermarriedf = ifelse(marital == 7, 1, 0))
df <- df %>% mutate(m_otherf = ifelse(marital == 3 |
  marital == 4 |
  marital == 6, 1, 0))

# union
df <- df %>% mutate(u_yesf = ifelse(unionmme == "Yes", 1, 0))
df <- df %>% mutate(u_nof = ifelse(unionmme == "No", 1, 0))

# higher power
df <- df %>% mutate(agesq = age^2, agecu = age^3)
```
# Data cleaning, Feature engineering

* Target Variable (Y): Hourly wage
* Predictor variables (X): Education (High school graduate as base), Race (White as base), Age, Sex (Male as base), Marital Status (Married as base), Union Status (Not in union as base)
* For more information see in Appendix

```{r, echo=FALSE, message=FALSE}

# creating models

# Model 1: linear regression on age
model1 <- as.formula(earnho ~ age + agesq)

# Models 2-5: Multiple linear regressions
model2 <- as.formula(earnho ~ age + agesq + s_femalef)

model3 <- as.formula(earnho ~ age + agesq + s_femalef + u_yesf + m_divorcedf
  + m_nevermarriedf + m_otherf)

model4 <- as.formula(earnho ~ age + agesq + s_femalef + u_yesf + m_divorcedf
  + m_nevermarriedf + m_otherf + r_blackf + r_asianf
  + r_otherf + e_collegedrop + e_occupationdegree
  + e_academicdegree)

model5 <- as.formula(earnho ~ age + agesq + s_femalef + u_yesf + m_divorcedf
  + m_nevermarriedf + m_otherf + r_blackf + r_asianf
  + r_otherf + e_collegedrop + e_occupationdegree
  + e_academicdegree + agecu + age * s_femalef + age * u_yesf)

# Running simple OLS
reg1 <- feols(model1, data = df, vcov = "hetero")
reg2 <- feols(model2, data = df, vcov = "hetero")
reg3 <- feols(model3, data = df, vcov = "hetero")
reg4 <- feols(model4, data = df, vcov = "hetero")
reg5 <- feols(model5, data = df, vcov = "hetero")
```

# Models

* Model 1: age, age squared
* Model 2: age, age squared, sex
* Model 3: age, age squared, sex, union, marital status
* Model 4: age, age squared, sex, union, marital status, race, education
* Model 5: age, age squared, sex, union, marital status, race, education, interaction age and female, interaction with age and union 

```{r, echo=FALSE}

# cross fold validation

# number of folds
k <- 4

set.seed(1)
cv1 <- train(model1, df, method = "lm", trControl = trainControl(method = "cv", number = k))
set.seed(1)
cv2 <- train(model2, df, method = "lm", trControl = trainControl(method = "cv", number = k))
set.seed(1)
cv3 <- train(model3, df, method = "lm", trControl = trainControl(method = "cv", number = k), na.action = "na.omit")
set.seed(1)
cv4 <- train(model4, df, method = "lm", trControl = trainControl(method = "cv", number = k), na.action = "na.omit")
set.seed(1)
cv5 <- train(model5, df, method = "lm", trControl = trainControl(method = "cv", number = k), na.action = "na.omit")
```

```{r, echo=FALSE}

# Calculate RMSE for each fold and the average RMSE as well
cv <- c("cv1", "cv2", "cv3", "cv4", "cv5")
rmse_cv <- c()

for (i in 1:length(cv)) {
  rmse_cv[i] <- sqrt((get(cv[i])$resample[[1]][1]^2 +
    get(cv[i])$resample[[1]][2]^2 +
    get(cv[i])$resample[[1]][3]^2 +
    get(cv[i])$resample[[1]][4]^2) / 4)
}


# summarize results
cv_mat <- data.frame(
  rbind(cv1$resample[4], "Average"),
  rbind(cv1$resample[1], rmse_cv[1]),
  rbind(cv2$resample[1], rmse_cv[2]),
  rbind(cv3$resample[1], rmse_cv[3]),
  rbind(cv4$resample[1], rmse_cv[4]),
  rbind(cv5$resample[1], rmse_cv[5])
)


m_comp <- c()
models <- c("reg1", "reg2", "reg3", "reg4", "reg5")
for (i in 1:length(cv)) {
  m_comp[i] <- length(get(models[i])$coefficient - 1)
}

m_comp <- tibble(
  model = models,
  complexity = m_comp,
  RMSE = rmse_cv
)

pcomp <- ggplot(m_comp, aes(x = complexity, y = RMSE)) +
  geom_point(color = "red", size = 2) +
  geom_line(color = "blue", size = 0.5) +
  labs(
    x = "Number of explanatory variables", y = "Averaged RMSE on test samples",
    title = "Prediction performance and model compexity"
  ) +
  theme_bw()
```
\newpage

# Appendix

```{r, echo=FALSE, message=FALSE, warning=FALSE}

p1 <- ggplot(df, aes(earnho)) +
  geom_density() +
  theme_bw() +
  labs(title = "Density of Hourly Wage", x = "", y = "")

p2 <- ggplot(df, aes(grade92)) +
  geom_histogram(stat = "count") +
  theme_bw() +
  labs(title = "Histogram of the Job types", x = "", y = "")

p3 <- ggplot(df, aes(race)) +
  geom_histogram(stat = "count") +
  theme_bw() +
  labs(title = "Histogram of the Races", x = "", y = "") +
  scale_x_continuous(breaks = 1:7) +
  xlim(1,7)

p4 <- ggplot(df, aes(age)) +
  geom_density() +
  theme_bw() +
  labs(title = "Density of the Ages", x = "", y = "")

p5 <- ggplot(df, aes(sex)) +
  geom_histogram(stat = "count") +
  theme_bw() +
  labs(title = "Histogram of the Sexes", x = "", y = "") +
  scale_x_continuous(breaks = 1:2)

p6 <- ggplot(df, aes(marital)) +
  geom_histogram(stat = "count") +
  theme_bw() +
  labs(title = "Histogram of the Marital status", x = "", y = "") +
  scale_x_continuous(breaks = 1:7)

p7 <- ggplot(df, aes(unionmme)) +
  geom_histogram(stat = "count") +
  theme_bw() +
  labs(title = "Histogram of the Union Status", x = "", y = "")
```

## Distribution of the hourly wages

```{r, echo=FALSE}
p1
```

The distribution is normal with right long tail

```{r, echo=FALSE, message=FALSE, warning=FALSE}
ggarrange(p2,p3,p4,p5,p6,p7)
```
\newpage

```{r, echo=FALSE}
pcomp
```

```{r, echo=FALSE}

# cross fold table
cv_mat %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("hold_position", "scale_down"))
```

With 5-fold cross validation Model 3 has the best RMSE 

\newpage

# Evaluation of the models using all the sample
```{r, echo=FALSE}

# coeff table
varname_report <- c(
  "(Intercept)" = "Intercept",
  "agesq" = "age squared",
  "s_femalef" = "female",
  "u_yesf" = "unionized",
  "m_divorcedf" = "divorced",
  "m_nevermarriedf" = "never married",
  "m_otherf" = "other marital status",
  "r_blackf" = "black",
  "r_asianf" = "asian",
  "r_otherf" = "other race",
  "e_collegedrop" = "college drop-out",
  "e_occupationdegree" = "occupational degree",
  "e_academicdegree" = "academic degree",
  "agecu" = "age cubed",
  "m_otherf" = "other marital status",
  "age x s_femalef" = "age x female",
  "age x u_yesf" = "age x unionized"
)

fitstat_register("k", function(x) {
  length(x$coefficients) - 1
}, "No. Variables")

etable(reg1, reg2, reg3, reg4, reg5,
  fitstat = c("aic", "bic", "rmse", "r2", "n", "k"),
  title = "Model Evaluation",
  se.below = T,
  dict = varname_report
) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("hold_position", "scale_down"))
```

According to BIC, Model 3 is the best. According to RMSE Model 5 is the best.
